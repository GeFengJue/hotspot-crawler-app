name: Scheduled Data Crawling

on:
  schedule:
    - cron: '*/15 * * * *'  # 每15分钟执行一次
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # 获取完整历史记录用于提交
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: pip install -r requirements.txt
      
    - name: Run crawler and get statistics
      id: run-crawler
      run: |
        # 运行爬虫并捕获输出
        python_output=$(python hotspot_crawler.py 2>&1)
        echo "$python_output"
        
        # 提取数据统计信息
        total_count=$(echo "$python_output" | grep "总共获取到" | awk '{print $3}')
        echo "total_count=$total_count" >> $GITHUB_OUTPUT
        
        # 保存爬虫输出到文件用于后续步骤
        echo "$python_output" > crawler_output.txt
        
    - name: Update hotspot data file
      run: python update_hotspot_data.py
      
    - name: Check for data changes
      id: check-changes
      run: |
        # 检查JSON文件的变化
        json_changed=false
        
        if ! git diff --quiet hotspot_data.json; then
          json_changed=true
        fi
        
        if [ "$json_changed" = true ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "json_changed=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Import data to database
      if: steps.check-changes.outputs.changes == 'true'
      run: python database_manager.py
      
    - name: Trigger API deployment
      if: steps.check-changes.outputs.changes == 'true'
      run: |
        # 数据已更新，API服务需要重新部署以提供最新数据
        echo "✅ 数据库已更新，包含最新热点数据"
        echo "API服务将在下次请求时自动提供最新数据"
        
        # 如果有API服务运行，可以在这里添加重启逻辑
        # 在实际部署中，API服务应该配置为自动重新加载数据
        echo "如果使用独立的API服务器，请确保重启服务以加载最新数据"
        
    - name: Generate update summary
      run: |
        # 生成更新摘要
        if [ -f crawler_output.txt ]; then
          echo "📊 本次数据更新统计：" > update_summary.md
          echo "==========================" >> update_summary.md
          echo "" >> update_summary.md
          
          # 提取各类型数据数量
          echo "📈 数据分类统计：" >> update_summary.md
          grep "获取到" crawler_output.txt | while read line; do
            echo "- $line" >> update_summary.md
          done
          
          # 总数据量
          if [ -n "${{ steps.run-crawler.outputs.total_count }}" ]; then
            echo "" >> update_summary.md
            echo "✅ 总共获取到 ${{ steps.run-crawler.outputs.total_count }} 条热点数据" >> update_summary.md
          fi
          
          # 更新时间
          echo "" >> update_summary.md
          echo "🕐 更新时间: $(date '+%Y-%m-%d %H:%M:%S')" >> update_summary.md
          
          echo "更新摘要已生成"
        fi
        
    - name: Commit and push data updates
      if: steps.check-changes.outputs.changes == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # 添加变化的文件
        if [ "${{ steps.check-changes.outputs.json_changed }}" = "true" ]; then
          git add hotspot_data.json
        fi
        
        # 添加更新摘要文件
        if [ -f update_summary.md ]; then
          git add update_summary.md
        fi
        
        # 生成提交信息
        commit_message="Auto-update data files $(date +'%Y-%m-%d %H:%M:%S')"
        if [ -n "${{ steps.run-crawler.outputs.total_count }}" ]; then
          commit_message="📊 数据更新: ${{ steps.run-crawler.outputs.total_count }}条热点数据 $(date +'%H:%M:%S')"
        fi
        
        git commit -m "$commit_message"
        git push
        
        # 有数据更新时重置计数器
        echo "0" > no_changes_counter.txt
        echo "数据已更新，重置未更新计数器" >> update_summary.md
        
    - name: No changes notification
      if: steps.check-changes.outputs.changes == 'false'
      run: |
        echo "No database changes detected"
        
        # 检查连续未更新次数
        if [ -f no_changes_counter.txt ]; then
          current_count=$(cat no_changes_counter.txt)
          new_count=$((current_count + 1))
        else
          new_count=1
        fi
        
        echo $new_count > no_changes_counter.txt
        
        # 检查是否达到提醒阈值（16次 = 4小时）
        if [ $new_count -ge 16 ]; then
          echo "⚠️ 连续 $new_count 次未抓取到新内容！请检查爬虫程序" >> update_summary.md
          echo "连续 $new_count 次未更新，可能需要人工干预" > critical_alert.md
          
          # 重置计数器
          echo "0" > no_changes_counter.txt
        else
          echo "连续未更新次数: $new_count" >> update_summary.md
        fi
        
    - name: Check daily data freshness
      run: |
        # 检查当天是否有数据更新
        current_date=$(date +%Y-%m-%d)
        if ! grep -q "$current_date" hotspot_data.json 2>/dev/null; then
          echo "❌ 今天 ($current_date) 未抓取到任何新内容！" >> update_summary.md
          echo "当日无数据更新警报" > daily_alert.md
        fi
        
    - name: Send critical alerts
      if: always()
      run: |
        # 如果有严重警报，在这里可以添加通知逻辑（如发送邮件、Slack消息等）
        if [ -f critical_alert.md ]; then
          echo "发送严重警报..."
          cat critical_alert.md
          # 这里可以集成邮件、Slack、Discord等通知方式
        fi
        
        if [ -f daily_alert.md ]; then
          echo "发送当日无数据警报..."
          cat daily_alert.md
        fi